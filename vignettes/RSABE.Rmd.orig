---
title: "Reference-Scaled Average Bioequivalence"
lang: "en"
output:
  rmarkdown::html_vignette:
    css: vignette.css
    toc: true
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Reference-Scaled Average Bioequivalence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
<!-- RSABE.rmd is generated from RSABE.Rmd.orig. Please edit that file -->
<!-- Dont forget to run pre_compute.R if RSABE.Rmd.orig has changed    -->
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#"
)
```
<div class="top"><a class="toplink" href="#nav" title="&uArr; top">&nbsp;</a></div>
<div id="nav">
<ul>
<li>[Main Vignette](vignette.html)</li>
<li>[ABE](ABE.html "Average Bioequivalence")</li>
<li><span title="» You are here «">RSABE</span></li>
<li>[Non-Inferiority](NI.html)</li>
<li>[Dose-Proportionality](DP.html)</li>
<li>[Power Analysis](PA.html)</li>
</ul>
</div>
<h3>Details and examples of other methods are accessible via the menu bar on top of the page and in the <a href="https://cran.r-project.org/package=PowerTOST/PowerTOST.pdf" title="PDF">online manual</a> of all functions.</h3>
```{r setup}
library(PowerTOST) # attach the library
```
# Defaults

| Parameter | Argument | Purpose | Default |
|-|-|-------|-|
| $\small{\alpha}$ | `alpha` | Nominal level of the test | `0.05` |
| $\small{\pi}$ | `targetpower` | <span title="typically 0.80 – 0.90">Minimum desired power</span> | `0.80` |
| $\small{\theta_0}$ | `theta0` | ‘True’ or assumed T/R ratio | `0.90` |
| $\small{\theta_1}$ | `theta1` | Lower BE limit and PE constraint | `0.80` |
| $\small{\theta_2}$ | `theta2` | Upper BE limit and PE constraint | `1.25` |
| *CV* | `CV` | CV | none |
| design | `design` | Planned replicate design | <span title="partial replicate">`"2x3x3"`</span> |
| regulator | `regulator` | ‘target’ jurisdiction | `"EMA"` |
| nsims | `nsims` | Number of simulations | see below |
| nstart | `nstart` | Start if a previous run failed | none |
| imax | `imax` | Maximum number of iterations | `100` |
| print | `print` | Show information in the console? | `TRUE` |
| details | `details` | Show details of the sample size search? | `FALSE` |
| setseed | `setseed` | Issue a fixed seed of the random number generator? | `TRUE` |

Arguments `targetpower`, `theta0`, `theta1`, `theta2`, and `CV` have to be given as fractions, not in percent.\
The *CV* is the *within* (intra-) subject coefficient of variation. If one value is given, homoscedasticity (equal variances) is assumed and therefore, *CV*~wT~ = *CV*~wR~. If two values are given (*i.e.*, `CV = c(x, y)`) heteroscedasticity (unequal variances) is assumed, where `CV[1]` has to be *CV*~wT~ and `CV[2]` *CV*~wR~.

If simulating for power (`theta0` within the BE limits), `nsims` defaults to 100,000. If simulating for the empiric type I error (`theta0` set to one of the BE limits), `nsims` defaults to 1 million.

<h2>Implemented Designs</h2>
```
#    design                        name   df
#   "2x2x3"   2x2x3 replicate crossover 2n-3
#   "2x2x4"   2x2x4 replicate crossover 3n-4
#   "2x4x4"   2x4x4 replicate crossover 3n-4
#   "2x3x3"   partial replicate (2x3x3) 2n-3
#   "2x4x2"            Balaam’s (2x4x2)  n-2
#  "2x2x2r" Liu’s 2x2x2 repeated x-over 3n-2
```
The terminology of the `design` argument follows this pattern: `treatments x sequences x periods`.

With `foo(..., details = FALSE, print = FALSE)` results are given as a data frame<small> </small>^[R Documentation. *Data Frames.* 2020-05-02. [R-manual](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html).] with eleven columns `Design`, `alpha`,  `CVwT`, `CVwR`, `theta0`, `theta1`, `theta2`, `Sample size`, `Achieved power`, `Target power`, and `nlast`. To access *e.g.*, the sample size use either `foo(...)[1, 8]` or `foo(...)[["Sample size"]]`. We suggest to use the latter in your code for clarity.

<span class="hl">The estimated sample size gives always the *total* number of subjects (not subject/sequence – like in some other software packages).</span>

<h2>Conditions and Methods</h2><!-- not in the TOC -->

Regulatory conditions and methods of evaluation are different.
```{r cond, echo = FALSE}
L <- c(sprintf("%.4f", scABEL(CV = 0.5, regulator = "EMA")[["lower"]]),
       sprintf("%.4f", scABEL(CV = 0.57382, regulator = "HC")[["lower"]]),
       "none")
U <- c(sprintf("%.4f", scABEL(CV = 0.5, regulator = "EMA")[["upper"]]),
       sprintf("%.4f", scABEL(CV = 0.57382, regulator = "HC")[["upper"]]),
       "none")
res       <- data.frame(regulator = c("EMA", "HC", "FDA"),
                        CVswitch = 0.30,  CVcap = NA, r_const = NA,
                        L = L, U = U, pe_constr = NA, method = NA,
                        stringsAsFactors = FALSE)
x         <- unlist(reg_const(regulator = "EMA"))
res[1, c(2:4, 7:8)]  <- x[c(2, 4, 3, 5:6)]
x         <- unlist(reg_const(regulator = "HC"))
res[2, c(2:4, 7:8)]  <- x[c(2, 4, 3, 6:5)]
x         <- unlist(reg_const(regulator = "FDA"))
res[3, c(2:4, 7:8)]  <- x[c(2, 4, 3, 6:5)]
res[, 3]  <- sprintf("%.5f", as.numeric(res[, 3]))
res[3, 3] <- "none"
res[, 4]  <- signif(as.numeric(res[, 4]), 5)
print(res, row.names = FALSE)
```
`CVswitch` is the lower cap of scaling, *i.e.*, if *CV*~wR~ is below this value reference-scaling is not acceptable. The upper cap of scaling `CVcap` differes between the EMA and HC, whereas for the FDA scaling is unlimited. The regulatory constant `r_const` is used for calculating the expanded limits (EMA, HC) and ‘implied limits’ (FDA) based on *s*~wR~: $\small{\left [ L,U \right ]=100\cdot\exp (\mp 0.760\cdot s_{\textrm{wR}})}$\
Here `L` and `U` give the maximum acceptable expansion based on $\small{s_{\textrm{wR}}^{*}=\sqrt{\log_{e}(CV_\textrm{cap}^2)+1}}$. The point estimate constraint `pe_constr` [0.80, 1.25] is applicable in all regulations. Evaluation has to be performed by ANOVA (EMA) or a mixed-effects model (HC, FDA). For the latter intra-subject contrasts are a suffiently close approximation.
 
# Sample Size
## Highly Variable Drugs / Drug Products
Estimate the sample size for assumed intra-subject *CV* 0.55 (*CV*~wT~ = *CV*~wR~). Employ the defaults (`theta0 = 0.90`, `targetpower = 0.80`, `design = "2x3x3"`, `nsims = 1e5`).

### EMA
Average Bioequivalence with Expanding Limits (ABEL). Default `regulator = "EMA"`.\
Note that this approach is recommended in other jurisdictions as well (*e.g.*, the <span title="World Health Organisation">WHO</span>; <span title="Association of Southeast Asian Nations">ASEAN</span> States, Australia, Brazil, the East African Community, Egypt, the Eurasian Economic Union, New Zealand, the Russian Federation).
```{r ema1}
sampleN.scABEL(CV = 0.55)
```
<h2>Heterogenicity</h2>
Whilst in full replicate designs simulating via the ‘key’ statistics closely matches the ‘gold standard’ of subject simulations, this is less so for unequal variances in the partial replicate design if *CV*~wT~ > *CV*~wR~. Let us keep *CV*~w~ 0.55 and split variances by a ratio of 1.5 (*i.e.*, T has a higher variance than R).
```{r ema2}
CV <- signif(CVp2CV(CV = 0.55, ratio = 1.5), 4)
sampleN.scABEL(CV = CV, details = FALSE)
```
Although the runtime will be longer, we recommend the function `sampleN.scABEL.sdsims()` instead.
```{r ema3}
sampleN.scABEL.sdsims(CV = CV, details = FALSE)
```
The sample size is slightly larger.

Explore sample sizes for extreme heterogenicity (variance ratio 2.5) via the ‘key’ statistics and subject simulations (4- and 3-period full replicate and partial replicate designs).
```{r ema4}
CVp <- seq(0.40, 0.70, 0.05)
CV  <- signif(CVp2CV(CV = CVp, ratio = 2.5), 4)
res <- data.frame(CVp = CVp, CVwT = CV[, 1], CVwR = CV[, 2],
                  f4.key = NA, f4.ss = NA, # 4-period full replicate
                  f3.key = NA, f3.ss = NA, # 3-period full replicate
                  p3.key = NA, p3.ss = NA) # 3-period partial replicate
for (i in seq_along(CVp)) {
  res$f4.key[i] <- sampleN.scABEL(CV = CV[i, ], design = "2x2x4",
                                  print = FALSE,
                                  details = FALSE)[["Sample size"]]
  res$f4.ss[i]  <- sampleN.scABEL.sdsims(CV = CV[i, ], design = "2x2x4",
                                         print = FALSE,
                                         details = FALSE,
                                         progress = FALSE)[["Sample size"]]
  res$f3.key[i] <- sampleN.scABEL(CV = CV[i, ], design = "2x2x3",
                                  print = FALSE,
                                  details = FALSE)[["Sample size"]]
  res$f3.ss[i]  <- sampleN.scABEL.sdsims(CV = CV[i, ], design = "2x2x3",
                                         print = FALSE,
                                         details = FALSE,
                                         progress = FALSE)[["Sample size"]]
  res$p3.key[i] <- sampleN.scABEL(CV = CV[i, ], design = "2x3x3",
                                  print = FALSE,
                                  details = FALSE)[["Sample size"]]
  res$p3.ss[i]  <- sampleN.scABEL.sdsims(CV = CV[i, ], design = "2x3x3",
                                         print = FALSE,
                                         details = FALSE,
                                         progress = FALSE)[["Sample size"]]
}
print(res, row.names = FALSE)
```
As shown in the previous example, subject simulations are recommended for the partial replicate design. For full replicate designs simulations via the ‘key’ statistics give identical results and are recommended for speed reasons. In this example `sampleN.scABEL()` is 60times faster than `sampleN.scABEL.sdsims()`.\
However, if *CV*~wT~ ≤ *CV*~wR~ we get identical results via the ‘key’ statistics.

### Health Canada
Average Bioequivalence with Expanding Limits (ABEL). Defaults as above but `regulator = "HC"`.
```{r HC}
sampleN.scABEL(CV = 0.55, regulator = "HC")
```
### FDA
Apart from the FDA only required by China’s agency.
```{r FDA}
sampleN.RSABE(CV = 0.55)
```
Note the lower sample size compared to the other approaches (due to the different regulatory constant and unlimited scaling).

## Narrow Therapeutic Index Drugs (FDA)
Required by the FDA and currently under discussion by the Chinese authority.\
Assuming heteroscedasticity (*CV*~w~ 0.125, *σ*^2^ ratio 2.5, *i.e.*, T has a substantially higher variability than R). Details of the sample size search suppressed. Assess additionally which one of the three components (scaled, ABE, *s*~wT~/*s*~wR~ ratio) drives the sample size.
```{r NTID1}
CV <- signif(CVp2CV(CV = 0.125, ratio = 2.5), 4)
n  <- sampleN.NTIDFDA(CV = CV, details = FALSE)[["Sample size"]]
suppressMessages(power.NTIDFDA(CV = CV, n = n, details = TRUE))
```
The *s*~wT~/*s*~wR~ component shows the lowest power and hence, drives the sample size.  
Compare that with homoscedasticity (*CV*~wT~ = *CV*~wR~ = 0.125):
```{r NTID2}
CV <- 0.125
n  <- sampleN.NTIDFDA(CV = CV, details = FALSE)[["Sample size"]]
suppressMessages(power.NTIDFDA(CV = CV, n = n, details = TRUE))
```    
Here the scaled ABE component shows the lowest power and drives the sample size, which is much lower than in the previous example.

## Highly Variable Narrow Therapeutic Index Drugs (FDA)
Almost a contradiction in itself. Required for [dagibatran](https://www.accessdata.fda.gov/drugsatfda_docs/psg/Dabigatran%20etexilate%20mesylate_oral%20capsule_NDA%20022512_RV05-17.pdf "Recommended Jun 2012; Revised Sep 2015, Jul 2017") and [rivaroxaban](https://www.accessdata.fda.gov/drugsatfda_docs/psg/Rivaroxaban_oral%20tablet_22406_RC09-15.pdf "Recommended Sep 2015").\
Assuming homoscedasticity (*CV*~wT~ = *CV*~wR~ = 0.30). Employ the defaults (`theta0 = 0.95`, `targetpower = 0.80`, `design = "2x2x4"`, `nsims = 1e5`). Details of the sample size search suppressed.
```{r HVNTID1}
sampleN.HVNTID(CV = 0.30, details = FALSE)
```
Assuming heteroscedasticity (*CV*~w~ 0.30, *σ*^2^ ratio 2.5).
```{r HVNTID2}
CV <- signif(CVp2CV(CV = 0.125, ratio = 2.5), 4)
sampleN.HVNTID(CV = CV, details = FALSE)
```
In this case a substantially higher sample size is required since the variability of T is higher than the one of R.

# Power
Power can by calculated by the counterparts of the respective sample size functions (instead the argument `targetpower` use the argument `n` and provide the observed `theta0`), *i.e.*,\
`power.scABEL()`, `power.RSABE()`, `power.NTIDFDA()`, and `power.HVNTID()`.  

# Type I Error
Contrary to average bioequivalence, where the Null-hypothesis is based on fixed limits, in reference-scaling the Null is generated in face of the data (*i.e*, the limits are random variables).

Endrényi and Tóthfalusi (2009,^[Endrényi L, Tóthfalusi L. *Regulatory and study conditions for the determination of bioequivalence of highly variable drugs.* J Pharm Sci. 2009: 12(1); 138--49. [Open access](https://journals.library.ualberta.ca/jpps/index.php/JPPS/article/download/771/5275/0).] 2019^[Endrényi L, Tóthfalusi L. *Bioequivalence for highly variable drugs: regulatory agreements, disagreements, and harmonization.* J Pharmacokin Pharmacodyn. 2019: 46(2); 117--26. [doi:10.1007/s10928-019-09623-w](https://doi.org/10.1007/s10928-019-09623-w).]), Labes (2013^[Labes D. *‘alpha’ of scaled ABE?* BEBA Forum. Vienna, 2013. [Open access](https://forum.bebac.at/mix_entry.php?id=10202#top10202).]), Wonnemann *et al.* (2015^[Wonnemann M, Frömke C, Koch A. *Inflation of the Type I Error: Investigations on Regulatory Recommendations for Bioequivalence of Highly Variable Drugs.* Pharm Res. 2015: 32(1); 135--43. [doi:10.1007/s11095-014-1450-z](https://doi.org/10.1007/s11095-014-1450-z).]), Muñoz *et al.* (2016^[Muñoz J, Alcaide D, Ocaña J. *Consumer’s risk in the EMA and FDA regulatory approaches for bioequivalence in highly variable drugs.* Stat Med. 2016: 35(12); 1933--43. [doi:10.1002/sim.6834](https://doi.org/10.1002/sim.6834).]),
Labes and Schütz (2016^[Labes D, Schütz H. *Inflation of Type I Error in the Evaluation of Scaled Average Bioequivalence, and a Method for its Control.* Pharm Res. 2016: 33(11); 2805--14. [doi:10.1007/s11095-016-2006-1](https://doi.org/10.1007/s11095-016-2006-1).]), Tóthfalusi and Endrényi (2016,^[Tóthfalusi L, Endrényi L. *An Exact Procedure for the Evaluation of Reference-Scaled Average Bioequivalence.* AAPS J. 2016: 18(2); 476--89. [doi:10.1208/s12248-016-9873-6](https://doi.org/10.1208/s12248-016-9873-6).] 2017^[Tóthfalusi L, Endrényi L. *Algorithms for Evaluating Reference Scaled Average Bioequivalence: Power, Bias, and Consumer Risk.* Stat Med. 2017: 36(27); 4378--90. [doi:10.1002/sim.7440](https://doi.org/10.1002/sim.7440).]), Molins *et al.* (2017^[Molins E, Cobo E, Ocaña J. *Two-Stage Designs Versus European Scaled Average Designs in Bioequivalence Studies for Highly Variable Drugs: Which to Choose?* Stat Med. 2017: 36(30); 4777--88. 1650--67. [doi:10.1002/sim.7452](https://doi.org/10.1002/sim.7452).]), Deng and Zhou (2019^[Deng Y, Zhou X-H. *Methods to control the empirical type I error rate in average bioequivalence tests for highly variable drugs.* Stat Meth Med Res. 2019: 29(6). [doi:10.1177/0962280219871589](https://doi.org/10.1177/0962280219871589).]) showed that under certain conditions (EMA, Health Canada: *CV*~wR~ \~0.22--0.45, FDA: *CV*~wR~ ≤0.30) the type I error will be substantially inflated.\
Below the inflation region the study will be evaluated for ABE and the type I error controlled by the TOST. Above the inflation region the type I error is controlled by the PE restriction and for the EMA and Health Canada additionally by the upper cap of scaling.
```{r TIE1}
CV      <- 0.35
res     <- data.frame(n = NA, CV = CV, TIE = NA)
res$n   <- sampleN.scABEL(CV = CV, design = "2x2x4", print = FALSE,
                          details = FALSE)[["Sample size"]]
U       <- scABEL(CV = CV)[["upper"]]
res$TIE <- power.scABEL(CV = CV, n = res$n, theta0 = U, design = "2x2x4")
print(res, row.names = FALSE)
```
With \~0.0656 the type I error is inflated (significantly larger than the nominal $\small{\alpha}$ 0.05).

![**Fig. 1** Empiric type I error for the EMA’s ABEL, 4-period full replicate design.<br />Pink plane at nominal $\small{\alpha}$ 0.05. Contour lines enclose region of inflation.](figure8.png){width=450px}

A substantially higher inflation of the type I error was reported for the FDA’s model. However, Davit *et al.* (2012^[Davit BM, Chen ML, Conner DP, Haidar SH, Kim S, Lee CH, Lionberger RA, Makhlouf FT, Nwakama PE, Patel DT, Schuirmann DJ, Yu LX. *Implementation of a Reference-Scaled Average Bioequivalence Approach for Highly Variable Generic Drug Products by the US Food and Drug Administration.* AAPS J. 2012: 14(4); 915--24. [doi:10.1208/s12248-012-9406-x](https://doi.org/10.1208/s12248-012-9406-x).]) assessed the type I error not at the [‘implied limits’](#ImpLim) but with the [‘desired consumer risk model’](#DesCRM) if $\small{s_{\textrm{wR}}\geq s_0}$ (*CV*~wR~ ≥\~25.4\%) at $\small{\exp\left ( \log_{e}(1.25)/s_0 \sqrt{\log_{e}(CV_{\textrm{wR}}^2+1)} \right )}$. Some statisticians call the latter ‘hocus-pocus’. However, even with this approach the type I error is still –although less – inflated.
```{r TIE2}
res <- data.frame(CV = sort(c(seq(0.25, 0.32, 0.01), se2CV(0.25))),
                  impl.L = NA, impl.U = NA, impl.TIE = NA,
                  des.L = NA, des.U = NA, des.TIE = NA)
for (i in 1:nrow(res)) {
  res[i, 2:3] <- scABEL(CV = res$CV[i], regulator = "FDA")
  if (CV2se(res$CV[i]) <= 0.25) {
    res[i, 5:6] <- c(0.80, 1.25)
  } else {
    res[i, 5:6] <- exp(c(-1, +1)*(log(1.25)/0.25)*CV2se(res$CV[i]))
  }
  res[i, 4] <- power.RSABE(CV = res$CV[i], theta0 = res[i, 3],
                           design = "2x2x4", n = 32, nsims = 1e6)
  res[i, 7] <- power.RSABE(CV = res$CV[i], theta0 = res[i, 5],
                           design = "2x2x4", n = 32, nsims = 1e6)
}
print(signif(res, 4), row.names = FALSE)

```

![**Fig. 2** Empiric type I error for the FDA’s RSABE, 4-period full replicate design, n = 32.<br />Thick line ‘implied limits’ (max. TIE 0.147 at *CV*~wR~ 30\%).<br />Thin line ‘desired consumer risk model’ (max. TIE 0.0636 at *CV*~wR~ 25.4\%).](figure12.png){width=449px}

Various approaches were suggested to control the patient’s risk. The methods of Labes and Schütz (2016) and Molins *et al.* (2017) are implemented in the function `scABEL.ad()`. The method of Tóthfalusi and Endrényi (2017) is implemented in the function `power.RSABE2L.sds()`. 

## Iteratively adjusted α
If an inflated type I error is expected, $\small{\alpha}$ is adjusted based on the observed *CV*~wR~ and the study should be evaluated with a wider confidence interval (Labes and Schütz 2016). Implemented designs: `"2x3x3"` (default), `"2x2x3"`, `"2x2x4"`.\
No adjustment is suggested if the study’s conditions (*CV*~wR~, sample size, design) will not lead to an inflated type I error.
```{r TIE3}
CV <- 0.45
n  <- sampleN.scABEL(CV = CV, design = "2x2x4", print = FALSE,
                     details = FALSE)[["Sample size"]]
scABEL.ad(CV = CV, design = "2x2x4", n = n)
```
Inside the region of inflated type I errors.
```{r TIE4}
CV <- 0.35
n  <- sampleN.scABEL(CV = CV, design = "2x2x4", print = FALSE,
                     details = FALSE)[["Sample size"]]
scABEL.ad(CV = CV, design = "2x2x4", n = n)
```
An adjusted $\small{\alpha}$ of 0.0363 (*i.e.*, the 92.74\% CI) controls the patient’s risk. However, it leads to a slightly lower power (0.773 instead of 0.812).

In order to counteract this loss in power, we can adjust the sample size with the function `sampleN.scABEL.ad()`.
```{r TIE5}
CV <- 0.35
sampleN.scABEL.ad(CV = CV, design = "2x2x4")
```
We have to increase the sample size to 38 in order to maintain power. Since the type I error depends to a minor degree on the sample size as well, we have to adjust slightly more ($\small{\alpha}$ 0.0361 instead of 0.0363 with 34 subjects).

Since the observed *CV*~wR~ is not the true – unknown – one, Molins *et al.* recommended to ‘assume the worst’ and adjust for *CV*~wR~ 0.30 in all cases.
```{r TIE6, echo=FALSE}
CV  <- 0.35
des <- "2x2x4"
n   <- sampleN.scABEL(CV = CV, design = des, print = FALSE,
                      details = FALSE)[["Sample size"]]
res <- data.frame(method = c("EMA (nominal alpha)",
                             "Labes and Schütz",
                             "Molins et al."), adj = "yes",
                  alpha = 0.05, TIE = NA, power = NA,
                  stringsAsFactors = FALSE)
x <- scABEL.ad(CV = CV, n = n, design = "2x2x4", print = FALSE)
res$adj[1]   <- "no"
res$TIE[1]   <- x$TIE.unadj
res$power[1] <- x$pwr.unadj
res$alpha[2] <- x$alpha.adj
res$TIE[2]   <- x$TIE.adj
res$power[2] <- x$pwr.adj
x <- scABEL.ad(CV = 0.30, design = des, n = n, print = FALSE)
res$alpha[3] <- x$alpha.adj
res$TIE[3]   <- x$TIE.adj
res$power[3] <- power.scABEL(alpha = x$alpha.adj, CV = CV,
                             n = n, design = des)
res[, 3]     <- round(res[, 3], 5)
res[, 4]     <- round(res[, 4], 4)
res[, 5]     <- round(res[, 5], 3)
cat(paste0("CV = ", CV, ", n = ", n, ", design = \"", des, "\"\n")); print(res, row.names = FALSE)
```
Although Molin’s adjusted $\small{\alpha}$ controls the patient’s risk, it leads to a further loss in power.

Example with a *CV*~wR~ above the region of inflated type I errors (*i.e.*, >0.45).
```{r TIE7, echo=FALSE}
CV  <- 0.80
des <- "2x2x4"
n   <- sampleN.scABEL(CV = CV, design = des, print = FALSE,
                      details = FALSE)[["Sample size"]]
res <- data.frame(method = c("Labes and Schütz", "Molins et al."),
                  adj = "no", alpha = 0.05, TIE = NA, power = NA,
                  stringsAsFactors = FALSE)
x   <- scABEL.ad(CV = CV, n = n, design = des, print = FALSE)
res$TIE[1]   <- x$TIE.unadj
res$power[1] <- x$pwr.unadj
x   <- scABEL.ad(CV = 0.30, n = n, design = des, print = FALSE)
res$adj[2]   <- "yes"
res$alpha[2] <- x$alpha.adj
res$TIE[2]   <- x$TIE.adj
res$power[2] <- power.scABEL(alpha = x$alpha.adj, CV = CV,
                             n = n, design = "2x2x4")
res[, 3]     <- round(res[, 3], 5)
res$TIE      <- round(res$TIE, 4)
res$power    <- round(res$power, 3)
cat(paste0("CV = ", CV, ", n = ", n, ", design = \"", des, "\"\n")); print(res, row.names = FALSE)
```
For high variability the negative impact on power is substantial.

## ‘Exact’ Procedure
Proposed by Tóthfalusi and Endrényi (2016). Example of the ‘ncTOST’ method by the same authors (2017).  Implemented designs: `"2x3x3"` (default), `"2x2x3"`, `"2x2x4"`.
```{r exact}
CV <- 0.35
n  <- sampleN.scABEL(CV = CV, design = "2x2x4", print = FALSE,
                     details = FALSE)[["Sample size"]]
U  <- scABEL(CV = CV)[["upper"]]
# subject simulations and therefore, relatively slow
power.RSABE2L.sds(CV = CV, design = "2x2x4", theta0 = U,
                  n = n, SABE_test = "exact", nsims = 1e6,
                  progress = FALSE)
```
With \~0.0482 the patient’s risk is controlled. However, the regulatory acceptance is unclear.

# Helpers
## BE limits
### Expanded Limits (EMA, Health Canada){#ExpLim}
```{r explim}
CV  <- c(0.30, 0.40898, 0.50, 0.57382)
res <- data.frame(CV = CV, EMA.L = NA, EMA.U = NA, EMA.cap = "",
                  HC.L = NA, HC.U = NA, HC.cap = "",
                  stringsAsFactors = FALSE)
for (i in seq_along(CV)) {
  res[i, 2:3] <- sprintf("%.4f", scABEL(CV[i], regulator = "EMA"))
  res[i, 5:6] <- sprintf("%.3f", scABEL(CV[i], regulator = "HC"))
}
res$EMA.cap[res$CV <= 0.30]   <- res$HC.cap[res$CV <= 0.30] <- "lower"
res$EMA.cap[res$CV >= 0.50]   <- "upper"
res$HC.cap[res$CV >= 0.57382] <- "upper"
print(res, row.names = FALSE)
```
For both agencies the lower cap for scaling is 30\%. Whereas the upper cap for the EMA is at 50\% (expanded limits 69.84--143.19\%), for Health Canada it is at ~57.4\% (expanded limits 66.7--150.0\%).

### FDA
For the FDA there is no upper cap (scaling is unlimited).

#### ‘Implied’ Limits{#ImpLim}
```{r implim}
res <- data.frame(CV = c(0.25, se2CV(0.25), 0.275, 0.3, 0.5, 1.0),
                  impl.L = NA, impl.U = NA, cap = "",
                  stringsAsFactors = FALSE)
for (i in 1:nrow(res)) {
  res[i, 2:3] <- sprintf("%.4f", scABEL(CV = res$CV[i],
                                        regulator = "FDA"))
}
res$cap[res$CV <= 0.30] <- "lower"
res$CV <- sprintf("%.3f", res$CV)
print(res, row.names = FALSE)
```
#### Limits of the ‘desired consumer risk model’{#DesCRM}
```{r desrisk}
res <- data.frame(CV = c(0.25, se2CV(0.25), 0.275, 0.3, 0.5, 1.0),
                  des.L = NA, des.U = NA, cap = "",
                  stringsAsFactors = FALSE)
for (i in 1:nrow(res)) {
  if (CV2se(res$CV[i]) <= 0.25) {
    res[i, 2:3] <- sprintf("%.4f", c(0.80, 1.25))
  } else {
    res[i, 2:3] <- sprintf("%.4f",
                     exp(c(-1, +1)*(log(1.25)/0.25)*CV2se(res$CV[i])))
  }
}
res$cap[res$CV <= 0.30] <- "lower"
res$CV <- sprintf("%.3f", res$CV)
print(res, row.names = FALSE)
```

## Regulatory Settings
```{r regset}
reg <- c("EMA", "HC", "FDA")
for (i in 1:3) {
  print(reg_const(regulator = reg[i]))
  cat("\n")
}
```

# Authors{#authors}
|function|author(s)|
|---|-|
|`sampleN.scABEL`, `sampleN.RSABE`, `sampleN.NTIDFDA`, `sampleN.HVNTID`,<br />`power.scABEL`, `power.RSABE2L.sdsims`, `scABEL`, `reg_const`|Detlew Labes|
|`power.scABEL.sdsims`|<span style="white-space:nowrap">Detlew Labes, Benjamin Lang</span>|
|`sampleN.scABEL.ad`, `sampleN.scABEL.sdsims`, `sampleN.RSABE2L.sdsims`,<br />`scABEL.ad`|Helmut Schütz|

# License{#license}
<h4 class="author">Helmut Schütz `r Sys.Date()`</h4>
[GPL-3](https://cran.r-project.org/web/licenses/GPL-3 "GNU General Public License, Version 3")
