---
title: "README"
author: Helmut Schütz
output:
  github_document:
    toc: true
    toc_depth: 3
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# PowerTOST

The package contains functions to calculate power and estimate sample size for various study designs used in (not only bio-) equivalence studies.  
Built `r Sys.Date()` with R `r getRversion()`.

## Supported Designs

```{r, echo = FALSE}
library(PowerTOST)
designs <- known.designs()
print(designs[, c(2, 9, 3)], row.names = FALSE)
```

Although some replicate designs are more ‘popular’ than others, sample size estimations are valid for *all* of the following designs:

|design|type|sequences|
|:----:|:----:|---------|
|`2x2x4`|full|TRTR / RTRT|
|`2x2x4`|full|TRRT / RTTR|
|`2x2x4`|full|TTRR / RRTT|
|`2x2x3`|full|TRT / RTR|
|`2x2x3`|full|TRT / RTR|
|`2x3x3`|partial|TRR / RTR / RRT|

## Purpose

For various methods power can be *calculated* based on

  - nominal *α*, coefficient of variation (*CV*), deviation of test from reference (*θ*<sub>0</sub>), acceptance limits {*θ*<sub>1</sub>, *θ*<sub>2</sub>}, sample size (*n*), and design.

For all methods the sample size can be *estimated* based on

  - nominal *α*, coefficient of variation (*CV*), deviation of test from reference (*θ*<sub>0</sub>), acceptance limits {*θ*<sub>1</sub>, *θ*<sub>2</sub>}, target power, and design.

## Supported
### Power and Sample Size
Power covers balanced as well as unbalanced sequences in crossover or replicate designs and equal/unequal group sizes in two-group parallel designs. Sample sizes are always rounded up to achieve balanced sequences or equal group sizes.

  - Average Bioequivalence (with arbitrary *fixed* limits).
  - Two simultaneous TOST procedures.
  - Non-inferiority *t*-test.
  - Ratio of two means with normally distributed data on the original scale based on Fieller’s (‘fiducial’) confidence interval.
  - ‘Expected’ power in case of uncertain (estimated) variability and/or uncertain *θ*<sub>0</sub>.
  - Reference-scaled bioequivalence based on simulations.  
    - EMA: Average Bioequivalence with Expanding Limits (ABEL).  
    - FDA: Reference-scaled Average Bioequivalence (RSABE) for Highly Variable Drugs / Drug Products and Narrow Therapeutic Index Drugs (NTIDs).  
  - Iteratively adjust *α* to control the type I error in ABEL and RSABE.
  - Dose-Proportionality using the power model.

### Methods
  - Exact
    - Owen’s Q.
    - Direct integration of the bivariate non-central *t*-distribution.
  - Approximations
    - Non-central *t*-distribution.
    - ‘Shifted’ central *t*-distribution.

### Helpers
  - Calculate *CV* from *MSE* or *SE* (and vice versa).
  - Calculate *CV* from given confidence interval.
  - Calculate *CV<sub>wR</sub>* from the upper expanded limit of an ABEL study.
  - Confidence interval of *CV*.
  - Pool *CV* from several studies.
  - Confidence interval for given *α*, *CV*, point estimate, sample size, and design.
  - Calculate *CV<sub>wT</sub>* and *CV<sub>wR</sub>* from a (pooled) *CV<sub>w</sub>* assuming a ratio of intra-subject variances.
  - *p*-values of the TOST procedure.
  - Analysis tool for exploration/visualization of the impact of expected values (*CV*, *θ*<sub>0</sub>, reduced sample size due to dropouts) on power of BE decision.
  - Construct design matrices of incomplete block designs.

## Defaults
  * *α* 0.05, {*θ*<sub>1</sub>, *θ*<sub>2</sub>} (0.80, 1.25). Details of the sample size search (and the regulatory settings in reference-scaled average bioequivalence) are printed.
  * Note: In all functions values have to be given as ratios, not in percent.  

### Average Bioequivalence  
*θ*<sub>0</sub> 0.95, target power 0.80, design \"2x2\" (TR|RT), exact method (Owen’s Q).

### Reference-Scaled Average Bioequivalence  
*α* 0.05, point estimate constraint (0.80, 1.25), homoscedasticity (*CV<sub>wT</sup>* = *CV<sub>wR</sup>*),  scaling is based on *CV<sub>wR</sub>*, target power 0.80, design \"2x3x3\" (TRR|RTR|RRT), approximation by the non-central *t*-distribution, 100,000 simulations.

  - EMA, WHO, Health Canada, and many others: Average bioequivalence with expanding limits (ABEL).
  - FDA: RSABE.

#### Highly Variable Drugs / Drug Products  
*θ*<sub>0</sub> 0.90.

###### EMA
Regulatory constant `0.76`, upper cap of scaling at *CV<sub>wR</sup>* 50\%, evaluation by ANOVA.

###### Health Canada
Regulatory constant `0.76`, upper cap of scaling at *CV<sub>wR</sup>* ~57.4\%, evaluation by intra-subject contrasts.

###### FDA
Regulatory constant `log(1.25)/0.25`, linearized scaled ABE (Howe’s approximation).

#### Narrow Therapeutic Index Drugs (FDA)
*θ*<sub>0</sub> 0.975, regulatory constant `log(1.11111)/0.1`, upper cap of scaling at *CV<sub>wR</sup>* ~21.4\%, design \"2x2x4\" (TRTR|RTRT), linearized scaled ABE (Howe’s approximation), upper limit of the confidence interval of *s<sub>wT</sup>*/*s<sub>wR</sup>* ≤2.5.

### Dose-Proportionality
*β*<sub>0</sub> (slope) `1+log(0.95)/log(rd)` where `rd` is the ratio of the highest and lowest dose, target power 0.80, crossover design, details of the sample size search suppressed.

### Power Analysis
Minimum acceptable power 0.70. *θ*<sub>0</sub>, design, conditions, and sample size method depend on defaults of the respective approaches (ABE, ABEL, RSABE, NTID).

## Examples
Before running the examples attach the library.

```{r}
library(PowerTOST)
```
If not noted otherwise, defaults are employed.

### Parallel Design
Power for total *CV* 0.35, *θ*<sub>0</sub> 0.95, group sizes 52 and 49, design \"parallel\".
```{r}
power.TOST(CV = 0.35, theta0 = 0.95, n = c(52, 49), design = "parallel")
```

### Crossover Design
Sample size for assumed intra-subject *CV* 0.20.
```{r}
sampleN.TOST(CV = 0.20)
```
### Replicate Designs

#### ABE
Sample size for assumed intra-subject *CV* 0.45, *θ*<sub>0</sub> 0.90, 3-period full replicate design \"2x2x3\" (TRT|RTR).
```{r}
sampleN.TOST(CV = 0.45, theta0 = 0.90, design = "2x2x3")
```
Note that the conventional model assumes homoscedasticity. For heteroscedasticity we can ‘switch off’ all conditions of one of the methods for reference-scaled ABE. We assume a σ<sup>2</sup> ratio of ⅔ (*i.e.*, T has a lower variability than R). Only relevant columns of the data.frame shown.
```{r}
reg <- reg_const("USER", r_const = NA, CVswitch = Inf,
                 CVcap = Inf, pe_constr = FALSE)
CV  <- round(CVp2CV(CV = 0.45, ratio = 2/3), 4)
res <- sampleN.scABEL(CV=CV, design = "2x2x3", regulator = reg,
                      details = FALSE, print = FALSE)
print(res[c(3:4, 8:9)], row.names = FALSE)
```
Similar sample size because the pooled *CV* is still 0.45.

#### ABEL
Sample size assuming homoscedasticity (*CV<sub>w</sub>* = 0.45).
```{r}
sampleN.scABEL(CV = 0.45, details = TRUE)
```

#### RSABE
#### HVD(P)s
Sample size for a four-period full replicate study (TRTR|RTRT) assuming heteroscedasticity (*CV<sub>wT</sub>* 0.40, *CV<sub>wR</sub>* 0.50). Details of the sample size search suppressed.
```{r}
sampleN.RSABE(CV = c(0.40, 0.50), design = "2x2x4", details = FALSE)
```
#### NTIDs
Sample size assuming heteroscedasticity (*CV<sub>w</sub>* 0.125, σ<sup>2</sup> ratio 2.5, *i.e.*, T has a substantially higher variability than R). Assess additionally which one of the three components (scaled, ABE, *s<sub>wT</sub>*/*s<sub>wR</sub>* ratio) drives the sample size.
```{r}
CV <- signif(CVp2CV(CV = 0.125, ratio = 2.5), 4)
n  <- sampleN.NTIDFDA(CV = CV)[["Sample size"]]
suppressMessages(power.NTIDFDA(CV = CV, n = n, details = TRUE))
```
The *s<sub>wT</sub>*/*s<sub>wR</sub>* component shows the lowest power and hence, drives the sample size.  
Compare that with homoscedasticity (*CV<sub>wT</sub>* = *CV<sub>wR</sub>* = 0.125):
```{r}
CV <- 0.125
n  <- sampleN.NTIDFDA(CV = CV, details = FALSE)[["Sample size"]]
suppressMessages(power.NTIDFDA(CV = CV, n = n, details = TRUE))
```    
Here the scaled ABE component shows the lowest power and drives the sample size, which is much lower than in the previous example.

### Dose-Proportionality
*CV* 0.20, Doses 1, 2, and 8 units, *β*<sub>0</sub> 1, target power 0.90.
```{r}
sampleN.dp(CV = 0.20, doses = c(1, 2, 8), beta0 = 1, targetpower = 0.90)
```
Note that the acceptance range of the slope depends on the ratio of the highest and lowest doses (*i.e.*, it gets tighter for wider dose ranges and therefore, higher sample sizes will be required).  
In an exploratory setting wider equivalence margins {*θ*<sub>1</sub>, *θ*<sub>2</sub>} (0.50, 2.00) are recommended, which would translate in this example to an acceptance range of `0.66667 ... 1.3333` and a sample size of only six subjects.

### Power Analysis
Explore impact of deviations from assumptions (higher *CV*, higher deviation of *θ*<sub>0</sub> from 1, dropouts) on power. Assumed intra-subject *CV* 0.20, target power 0.90.
```{r}
res <- pa.ABE(CV = 0.20, targetpower = 0.90)
print(res)
```
If the study starts with 26 subjects (power \~0.92), the *CV* can increase to \~0.27 **or** *θ*<sub>0</sub> decrease to \~0.90 **or** the sample size decrease to 10 whilst power will still be ≥0.70.    
However, this is **not** a substitute for the “Sensitivity Analysis” recommended in [ICH-E9](https://www.ich.org/fileadmin/Public_Web_Site/ICH_Products/Guidelines/Efficacy/E9/Step4/E9_Guideline.pdf), since in a real study a combination of all effects occurs simultaneously. It is up to *you* to decide on reasonable combinations and analyze their respective power.

### Speed Comparisons
#### ABE
\"2x2\" crossover design, intra-subject *CV* 0.17. Explore sample sizes and achieved power for the supported methods (the 1<sup>st</sup> one is the default).
```{r}
CV   <- 0.17
expl <- data.frame(method = c("owenq", "mvt", "noncentral", "shifted"),
                   n = NA, power = NA, seconds = NA)
runs <- 20
for (i in 1:nrow(expl)) {
  start <- proc.time()[[3]]
  for (j in 1:runs) { # repeat to get better estimate of run times
    expl[i, 2:3] <- sampleN.TOST(CV = CV, method = expl$method[i],
                                 print = FALSE)[7:8]
  }
  expl[i, 4] <- (proc.time()[[3]] - start) / runs
}
print(expl, digits = 6, row.names = FALSE)
```
The 2<sup>nd</sup> exact method is substantially slower than the 1<sup>st</sup>. The approximation based on the noncentral *t*-distribution is slightly faster but matches the 1<sup>st</sup> exact method closely. The approximation based on the shifted central *t*-distribution is the fastest but might estimate a sample size higher than necessary. Hence, it should be used only for comparative purposes.

#### ABEL
\"2x2x4\" full replicate design (TRTR|RTRT), homogenicity (*CV<sub>wT</sub>* = *CV<sub>wR</sub>* 0.45). Explore sample sizes and achieved power for the supported methods (‘key’ statistics or subject simulations).
```{r}
CV           <- c(0.45, 0.45)
design       <- "2x2x4"
expl         <- data.frame(method = c("key statistics", "subject simulations"),
                           n = NA, power = NA, seconds = NA)
start        <- proc.time()[[3]]
expl[1, 2:3] <- sampleN.scABEL(CV = CV, design = design,
                               print = FALSE, details = FALSE)[8:9]
expl[1, 4]   <- proc.time()[[3]] - start
start        <- proc.time()[[3]]
expl[2, 2:3] <- sampleN.scABEL.sdsims(CV = CV, design = design,
                                      print = FALSE, details = FALSE)[8:9]
expl[2, 4]   <- proc.time()[[3]] - start
print(expl, row.names = FALSE)
```
Simulating via the ‘key’ statistics is the method of choice for speed reasons. However, subject simulations are recommended if

  - the partial replicate design (TRR|RTR|RRT) is planned *and*
  - the special case of heterogenicity *CV<sub>wT</sub>* > *CV<sub>wR</sub>* is expected.

## Installation
You can install the released version of PowerTOST from [CRAN](https://CRAN.R-project.org) with:
```{r}
package <- "PowerTOST"
inst    <- package %in% installed.packages()
if (length(package[!inst]) > 0) install.packages(package[!inst])
```
And the development version from [GitHub](https://github.com/) with:
```
# install.packages("devtools")
devtools::install_github("Detlew/PowerTOST")
```
